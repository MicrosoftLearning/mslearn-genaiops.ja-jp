---
lab:
  title: 生成 AI アプリケーションを監視する
---

# 生成 AI アプリケーションを監視する

この演習は約 **30** 分かかります。

> **注**: この演習では、Azure AI Foundry に関するある程度の知識を前提としているため、よりアクティブな探索と実践的な学習を促すために、一部の手順は意図的にあまり詳細に説明されていません。

## はじめに

この演習では、チャット補完アプリの監視を有効にして、そのパフォーマンスを Azure Monitor で確認します。 デプロイされたモデルとやり取りしてデータを生成し、生成されたデータを生成 AI アプリケーションの分析情報ダッシュボードで確認し、モデルのデプロイの最適化に役立つアラートを設定します。

## 1. 環境を設定する

この演習のタスクを完了するには、以下が必要です。

- Azure AI Foundry ハブ
- Azure AI Foundry プロジェクト
- デプロイされたモデル (GPT-4o など)
- 接続された Application Insights リソース

### A. AI Foundry ハブとプロジェクトを作成する

ハブとプロジェクトをすばやくセットアップするために、Azure AI Foundry ポータル UI を使用する簡易な手順を以下に示します。

1. Azure AI Foundry ポータルに移動します ([https://ai.azure.com](https://ai.azure.com) を開きます)。
1. Azure の資格情報を使用してサインインします。
1. プロジェクトを作成する:
    1. **[すべてのハブ + プロジェクト]** に移動します。
    1. **[+ New project]** を選択します。
    1. **プロジェクト名**を入力します。
    1. メッセージが表示されたら、**新しいハブを作成します**。
    1. ハブをカスタマイズする:

        1. **[サブスクリプション]**、**[リソース グループ]**、**[場所]** などを選択します。
        1. **新しい Azure AI サービス** リソースに接続します (AI 検索をスキップします)。

    1. 確認し、**[作成]** を選択します。

1. **デプロイが完了するまで待ちます** (1 から 2 分間)。

### B. モデルをデプロイする

監視できるデータを生成するには、まずモデルをデプロイして操作する必要があります。 手順では GPT-4o モデルをデプロイするように求められますが、使用可能な Azure OpenAI Service コレクションから**任意のモデルを使用できます**。

1. 左側のメニューを使用し、**[マイ アセット]** で **[モデル + エンドポイント]** ページを選択します。
1. **ベース モデル**をデプロイし、**gpt-4o** を選択します。
1. **デプロイの詳細をカスタマイズします**。
1. **[処理容量]** を **5K TPM (1 分あたりのトークン数)** に設定します。

ハブとプロジェクトの準備が整い、必要な Azure リソースがすべて自動的にプロビジョニングされます。

### C: Application Insights の接続

Application Insights を Azure AI Foundry のプロジェクトに接続して、監視するデータの収集を開始します。

1. Azure AI Foundry ポータルでプロジェクトを開きます。
1. 左側のメニューを使用し、**[トレース]** ページを選択します。
1. アプリに接続する Application Insights リソースを**新規作成**します。
1. **Application Insights リソースの名前**を入力します。

Application Insights がプロジェクトに接続され、分析のためにデータの収集が開始されます。

## 2. デプロイしたモデルを操作する

Azure Cloud Shell で Azure AI Foundry プロジェクトへの接続をセットアップして、デプロイしたモデルをプログラムで操作します。 これにより、モデルにプロンプトを送信し、監視データを生成できます。

### A. Cloud Shell を使用してモデルと接続する

まず、モデルとやり取りするための認証に必要な情報を取得します。 次に、Azure Cloud Shell にアクセスし、指定されたプロンプトを独自のデプロイ済みモデルに送信するように構成を更新します。

1. Azure AI Foundry ポータルで、プロジェクトの **[概要]** ページを表示します。
1. **[プロジェクトの詳細]** エリアで、**[プロジェクト接続文字列]** の内容を書き留めます。
1. その文字列をメモ帳に**保存**します。 この接続文字列を使用して、クライアント アプリケーションでプロジェクトに接続します。
1. 新しいブラウザー タブを開きます (既存のタブで Azure AI Foundry ポータルを開いたままにします)。
1. 新しいブラウザー タブで [Azure portal](https://portal.azure.com) (`https://portal.azure.com`) を参照し、メッセージに応じて Azure 資格情報を使用してサインインします。
1. ページ上部の検索バーの右側にある **[\>_]** ボタンを使用して、Azure portal に新しい Cloud Shell を作成し、サブスクリプションにストレージがない ***PowerShell*** 環境を選択します。
1. Cloud Shell ツール バーの **[設定]** メニューで、**[クラシック バージョンに移動]** を選択します。

    **<font color="red">続行する前に、クラシック バージョンの Cloud Shell に切り替えたことを確認します。</font>**

1. Cloud Shell ペインで、次のコマンドを入力して実行します。

    ```
    rm -r mslearn-genaiops -f
    git clone https://github.com/microsoftlearning/mslearn-genaiops mslearn-genaiops
    ```

    このコマンドは、この演習のコード ファイルを含んだ GitHub リポジトリを複製します。

1. リポジトリが複製されたら、アプリケーション コード ファイルを含んだフォルダーに移動します。  

    ```
   cd mslearn-genaiops/Files/07
    ```

1. Cloud Shell コマンド ライン ペインで、次のコマンドを入力して、必要なライブラリをインストールします。

    ```
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install python-dotenv azure-identity azure-ai-projects azure-ai-inference azure-monitor-opentelemetry
    ```

1. 次のコマンドを入力して、提供されている構成ファイルを開きます。

    ```
   code .env
    ```

    このファイルをコード エディターで開きます。

1. コード ファイルで以下を行います。

    1. **your_project_connection_string** プレースホルダーをプロジェクトの接続文字列 (Azure AI Foundry ポータルでプロジェクトの **[概要]** ページからコピーしたもの) に置き換えます。
    1. **your_model_deployment** プレースホルダーを、GPT-4o モデル デプロイに割り当てた名前 (既定では `gpt-4o`) に置き換えます。

1. プレースホルダーを*置き換えたら、* コード エディターで、**Ctrl + S** コマンドを使用するか、**右クリックして [保存]** を選択し、**変更を保存します**。

### B. デプロイ済みモデルにプロンプトを送信する

異なるプロンプトをデプロイ済みモデルに送信する複数のスクリプトを実行します。 これらのやり取りにより、Azure Monitor で後から確認できるデータが生成されます。

1. 次のコマンドを実行して、提供されている**最初のスクリプトを表示**します。

    ```
   code start-prompt.py
    ```

1. コード エディターの下の Cloud Shell コマンド ライン ペインで、次のコマンドを入力して**スクリプトを実行**します。

    ```
   python start-prompt.py
    ```

    応答がモデルによって生成され、さらに分析するために Application Insights でキャプチャされます。 その効果を調べるために、プロンプトを変えてみましょう。

1. **スクリプトを開いて確認します**。ここでは、プロンプトは、**1 つの文とリストで回答するようにとだけモデルに指示しています**。

    ```
   code short-prompt.py
    ```

1. コマンド ラインで次のコマンドを入力して、**スクリプトを実行**します。

    ```
   python short-prompt.py
    ```

1. 次のスクリプトの目的も同様ですが、ユーザー メッセージではなく**システム メッセージ**での出力を求める指示が含まれています。

    ```
   code system-prompt.py
    ```

1. コマンド ラインで次のコマンドを入力して、**スクリプトを実行**します。

    ```
   python system-prompt.py
    ```

1. 最後に、**多数のトークン**を含むプロンプトを実行して、エラーをトリガーしてみましょう。

    ```
   code error-prompt.py
    ```

1. コマンド ラインで次のコマンドを入力して、**スクリプトを実行**します。 **エラーが発生する可能性が非常に高い**ことに注意してください。

    ```
   python error-prompt.py
    ```

これで、モデルとやり取りしたので、Azure Monitor でデータを確認できます。

> **注**: 監視データが Azure Monitor に表示されるまでに数分かかる場合があります。

## 4. Azure Monitor に監視データを表示する

モデルとのやり取りの結果収集されたデータを表示するには、Azure Monitor で、ブックにリンクしているダッシュボードにアクセスします。

### A. Azure AI Foundry ポータルから Azure Monitor に移動する

1. **Azure AI Foundry ポータル**が開いている、ブラウザーのタブに移動します。
1. 左側のメニューを使用し、**[トレース]** を選択します。
1. 上部にある、**生成 AI アプリケーションに関する分析情報ダッシュボードを確認する**ためのリンクを選択します。 Azure Monitor が新しいタブで開きます。
1. **[概要]** で、デプロイ済みモデルとのやり取りの概要データを確認します。

## 5. Azure Monitor で監視メトリックを解釈する

次は、データを詳細に調べて、何を意味しているかを解釈していきます。

### A. トークンの使用状況を確認する

まず **[トークンの使用状況]** セクションに注目し、次のメトリックを確認します。

- **プロンプト トークン**: モデル呼び出し全体を通して入力 (送信したプロンプト) で使用されたトークンの合計数。

> これは、モデルに*質問するコスト*と考えてください。

- **完了トークン**: モデルが出力として返したトークンの数 (基本的には応答の長さ)。

> 生成された完了トークンは、多くの場合、トークンの使用量とコストの大部分を表します。長い回答や詳細な回答の場合は、特にそうです。

- **合計トークン**: プロンプト トークンと完了トークンを合算したもの。

> 待ち時間とコストの増加につながるため、課金とパフォーマンスの面で最も重要なメトリックです。

- **呼び出しの合計数**: 個別の推論要求の数。これは、モデルが呼び出された回数です。

> スループットを分析し、呼び出しあたりの平均コストを把握するのに役立ちます。

### B. 個々のプロンプトを比較する

下にスクロールして、**[生成 AI のスパン]** を見つけます。これは、各プロンプトが新しいデータ行として表されるテーブルとして視覚化されます。 次の列の内容を確認し比較します。

- **状態**: モデル呼び出しが成功したか失敗したかを示します。

> これを使用すると、問題のあるプロンプトや構成エラーを特定できます。 最後のプロンプトは、長すぎたために失敗した可能性があります。

- **期間**: モデルの応答にかかった時間 (ミリ秒単位) を示します。

> 行全体を比較して、結果的に処理時間が長くなるプロンプトのパターンを調べます。

- **入力**: モデルに送信されたユーザー メッセージを表示します。

> この列を使用すると、どのプロンプト定式化が効率的かまたは問題があるかを評価することができます。

- **システム**: プロンプトで使用されているシステム メッセージを表示します (存在する場合)。

> エントリを比較すると、システム メッセージの使用または変更による影響を評価することができます。

- **出力**: モデルの応答を含んでいます。

> これを使用すると、詳細度、関連度、一貫性を評価できます。 特に、トークンの数と期間に関連します。

## 6. (オプション) アラートを作成する

時間に余裕があれば、モデルの待ち時間が特定のしきい値を超えたときに通知するアラートを設定してみてください。 これは、チャレンジ課題となるように設計された演習です。つまり、手順はわざとあまり詳細に説明されていません。

- Azure Monitor で、Azure AI Foundry プロジェクトとモデルの**新しいアラート ルール**を作成します。
- **要求期間 (ミリ秒)** などのメトリックを選択し、しきい値 (たとえば 4000 ミリ秒など) を定義します。
- **新しいアクション グループ**を作成して、通知方法を定義します。

アラートは、プロアクティブな監視を確立するので、運用環境の準備に役立ちます。 構成するアラートは、プロジェクトの優先順位と、リスクの測定や軽減の方法をチームがどのように決定したかによって異なります。

## 他のラボの参照先

その他のラボと演習については、[Azure AI Foundry ラーニング ポータル](https://ai.azure.com)で調べてください。また、他の利用可能なアクティビティについては、このコースの**ラボ セクション**をご覧ください。
