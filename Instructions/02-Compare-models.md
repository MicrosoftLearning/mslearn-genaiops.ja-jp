---
lab:
  title: モデル カタログの言語モデルを比較する
  description: モデルを比較し、生成 AI プロジェクトに適したモデルを選択する方法について学習します。
---

## モデル カタログの言語モデルを比較する

ユース ケースを定義したら、モデル カタログを使用して、AI モデルによって問題が解決されるかどうかを調べることができます。 モデル カタログを使用してデプロイするモデルを選択し、それを比較して、ニーズに最も適したモデルを調べることができます。

この演習では、Azure AI Foundry ポータルのモデル カタログを使用して 2 つの言語モデルを比較します。

この演習には約 **30** 分かかります。

## シナリオ

受講生が Python でコーディングする方法を学ぶのを手助けするアプリを構築したいとします。 このアプリでは、受講生がコードを記述して評価するのを手助けする自動チューターが必要です。 1 つの演習では、受講生は次の例の画像に基づいて、円グラフをプロットするために必要な Python コードを思い付く必要があります。

![数学 (34.9%)、物理 (28.6%)、化学 (20.6%)、英語 (15.9%) のセクションを含む試験で取得したマークを示す円グラフ](./images/demo.png)

画像を入力として受け入れ、正確なコードを生成できる言語モデルを選択する必要があります。 これらの条件を満たす使用可能なモデルは、GPT-4o と GPT-4o mini です。

まず、Azure AI Foundry ポータルでこれらのモデルを操作するために必要なリソースをデプロイします。

## Azure AI ハブとプロジェクトを作成する

Azure AI Foundry ポータルを使用して Azure AI ハブとプロジェクトを手動で作成したり、演習で使用するモデルをデプロイしたりできます。 ただし、[Azure Developer CLI (azd)](https://aka.ms/azd) でテンプレート アプリケーションを使用して、このプロセスを自動化することもできます。

1. Web ブラウザーで、`https://portal.azure.com`にある [Azure portal](https://portal.azure.com) を開き、自分の Azure 資格情報を使用してサインインします。

1. ページ上部の検索バーの右側にある **[\>_]** ボタンを使用して、Azure portal に新しい Cloud Shell を作成します。***PowerShell*** 環境を選択します。 Azure portal の下部にあるペインに、Cloud Shell のコマンド ライン インターフェイスが表示されます。 Azure Cloud Shell の使い方について詳しくは、[Azure Cloud Shell のドキュメント](https://docs.microsoft.com/azure/cloud-shell/overview)をご覧ください。

    > **注**: *Bash* 環境を使用するクラウド シェルを以前に作成した場合は、それを ***PowerShell*** に切り替えます。

1. Cloud Shell ツール バーの **[設定]** メニューで、**[クラシック バージョンに移動]** を選択します。

    **<font color="red">続行する前に、クラシック バージョンの Cloud Shell に切り替えたことを確認します。</font>**

1. PowerShell ペインで、次のコマンドを入力して、この演習のリポジトリを複製します。

     ```powershell
    rm -r mslearn-genaiops -f
    git clone https://github.com/MicrosoftLearning/mslearn-genaiops
     ```

1. リポジトリが複製されたら、次のコマンドを入力してスターター テンプレートを初期化します。 
   
     ```powershell
    cd ./mslearn-genaiops/Starter
    azd init
     ```

1. プロンプトが表示されたら、新しい環境に名前を付けます。これは、プロビジョニングされたすべてのリソースに一意の名前を付けるために使用されます。
        
1. 次に、次のコマンドを入力してスターター テンプレートを実行します。 依存リソース、AI プロジェクト、AI サービス、オンライン エンドポイントを使用して AI ハブをプロビジョニングします。 また、モデル GPT-4o と GPT-4o mini もデプロイします。

     ```powershell
    azd up
     ```

1. メッセージが表示されたら、使用するサブスクリプションを選択してから、リソース プロビジョニング用に次のいずれかの場所を選択します。
   - 米国東部
   - 米国東部 2
   - 米国中北部
   - 米国中南部
   - スウェーデン中部
   - 米国西部
   - 米国西部 3
    
1. スクリプトの完了まで待ちます。通常、約 10 分かかりますが、さらに時間がかかる場合もあります。

    > **注**: Azure OpenAI リソースは、リージョンのクォータによってテナント レベルで制限されます。 上で一覧表示されているリージョンには、この演習で使用されるモデル タイプの既定のクォータが含まれています。 リージョンをランダムに選択すると、1 つのリージョンがクォータ制限に達するリスクが軽減されます。 クォータ制限に達した場合は、別のリージョンに別のリソース グループを作成する必要が生じる可能性があります。 詳しくは、[リージョンごとのモデルの可用性](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models?tabs=standard%2Cstandard-chat-completions#global-standard-model-availability)を参照してください

    <details>
      <summary><b>トラブルシューティングのヒント</b>: 特定のリージョンには使用可能なクォータがありません</summary>
        <p>選択したリージョンに使用可能なクォータがないためにいずれかのモデルに対してデプロイ エラーが発生した場合は、次のコマンドを実行してみてください。</p>
        <ul>
          <pre><code>azd env set AZURE_ENV_NAME new_env_name
   azd env set AZURE_RESOURCE_GROUP new_rg_name
   azd env set AZURE_LOCATION new_location
   azd up</code></pre>
        <code>new_env_name</code>、<code>new_rg_name</code>、および<code>new_location</code>を新しい値に置き換えます。 新しい場所は、演習の開始時に一覧表示されるリージョン (<code>eastus2</code>、<code>northcentralus</code>など) のいずれかである必要があります。
        </ul>
    </details>

## モデルを比較する

Azure によって完全に管理される推論インフラストラクチャを持つ、画像を入力として受け入れるモデルが 3 つあります。 ここでは、それらを比較して、ユース ケースに最適なものを決定する必要があります。

1. 新しいブラウザー タブで、[Azure AI Foundry ポータル](https://ai.azure.com) (`https://ai.azure.com`) を開き、Azure 資格情報を使用してサインインします。
1. メッセージが表示されたら、先ほど作成した AI プロジェクトを選択します。
1. 左側のメニューを使用して、**[モデル カタログ]** ページに移動します。
1. **[モデルの比較]** を選択します (検索ウィンドウのフィルターの横にあるボタンを見つけます)。
1. 選択したモデルを削除します。
1. 比較する 3 つのモデルを 1 つずつ追加します: **gpt-4o**、**gpt-4o-mini**。 **GPT-4** については、選択したバージョンが **turbo-2024-04-09** であることを確認します。それが画像を入力として受け入れる唯一のバージョンだからです。
1. X 軸を **[正確性]** に変更します。
1. Y 軸が **[コスト]** に設定されていることを確認します。

プロットを確認し、次の質問に答えてみてください。

- *より正確なモデルはどれですか?*
- *どのモデルを使用する方が安いですか?*

ベンチマーク メトリックの正確性は、一般公開されている汎用データセットに基づいて計算されます。 プロットから、トークンあたりのコストは最も高くても正確性は最も高くないため、モデルの 1 つをまず除外できます。 最終決定する前に、ユース ケースに固有の残りの 2 つのモデルの出力の品質を調べてみましょう。

## Cloud Shell で開発環境を設定する

実験と反復処理をすばやく行うには、Cloud Shell で一連の Python スクリプトを使用します。

1. Azure portal タブに戻り、先ほどデプロイ スクリプトによって作成されたリソース グループに移動し、**Azure AI Foundry** リソースを選択します。
1. リソースの**概要**ページで、**こちらをクリックしてエンドポイントを表示し**、AI Foundry の API エンドポイントをコピーします。
1. エンドポイントをメモ帳に保存します。 これを使用して、クライアント アプリケーションでプロジェクトに接続します。
1. Azure Portal タブに戻り、前に Cloud Shell を閉じた場合は Cloud Shell を開き、次のコマンドを実行して、この演習で使用するコード ファイルを含むフォルダーに移動します。

     ```powershell
    cd ~/mslearn-genaiops/Files/02/
     ```

1. Cloud Shell コマンド ライン ペインで、次のコマンドを入力して、必要なライブラリをインストールします。

    ```powershell
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install python-dotenv azure-identity azure-ai-projects openai matplotlib
    ```

1. 次のコマンドを入力して、提供されている構成ファイルを開きます。

    ```powershell
   code .env
    ```

    このファイルをコード エディターで開きます。

1. コード ファイルで、**your_project_endpoint** プレースホルダーを、前にコピーしたプロジェクトのエンドポイントに置き換えます。 演習で使用する 1 番目と 2 番目のモデルがそれぞれ **gpt-4o** と **gpt-4o-mini** であることを確認します。
1. プレースホルダーを置き換えた "後"、コード エディター内で、**CTRL + S** コマンドまたは**右クリック > [保存]** を使用して変更を保存し、**CTRL + Q** コマンドまたは**右クリック > [終了]** を使用して、Cloud Shell コマンド ラインを開いたままコード エディターを閉じます。**

## デプロイ済みモデルにプロンプトを送信する

次に、デプロイ済みモデルに異なるプロンプトを送信する複数のスクリプトを実行します。 これらのやり取りにより、後で Azure Monitor で確認できるデータが生成されます。

1. 次のコマンドを実行して、提供されている**最初のスクリプトを表示**します。

    ```powershell
   code model1.py
    ```

スクリプトは、この演習で使用する画像をデータ URL にエンコードします。 この URL は、チャット入力候補要求に、最初のテキスト プロンプトと共に画像を直接埋め込むために使用されます。 次に、スクリプトはモデルの応答を出力し、それをチャット履歴に追加し、2 番目のプロンプトを送信します。 2 番目のプロンプトは、後で観察されるメトリックをより重要なものにするために送信され、保存されますが、コードの省略可能セクションのコメントを解除して、2 番目の応答を出力として使用することもできます。

1. Cloud Shell コマンド ライン ペインで、次のコマンドを入力してアプリを実行します。

    ```
   az login
    ```

    **<font color="red">Cloud Shell セッションが既に認証されている場合でも、Azure にサインインする必要があります。</font>**

    > **注**: ほとんどのシナリオでは、*az ログイン*を使用するだけで十分です。 ただし、複数のテナントにサブスクリプションがある場合は、*[--tenant]* パラメーターを使用してテナントを指定する必要があります。 詳細については、「[Azure CLI を使用して対話形式で Azure にサインインする](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)」を参照してください。
    
1. メッセージが表示されたら、指示に従って新しいタブでサインイン ページを開き、指定された認証コードと Azure 資格情報を入力します。 次に、コマンド ラインでサインイン プロセスを完了し、プロンプトが表示されたら、Azure AI Foundry ハブを含むサブスクリプションを選択します。
1. サインインしたら、次のコマンドを入力してアプリケーションを実行します。

    ```powershell
   python model1.py
    ```

    応答がモデルによって生成され、さらに分析するために Application Insights でキャプチャされます。 2 番目のモデルを使用して、それらの違いを調べてみましょう。

1. コード エディターの下にある Cloud Shell コマンド ライン ペインで、次のコマンドを入力して **2 番目**のスクリプトを実行します。

    ```powershell
   python model2.py
    ```

    両方のモデルからの出力が得られましたが、何か違いはありますか? 

    > **注**:必要に応じて、コード ブロックをコピーし、コマンド `code your_filename.py` を実行し、エディターにコードを貼り付け、ファイルを保存してからコマンド `python your_filename.py`を実行すると、回答として提示されたスクリプトをテストできます。 スクリプトが正常に実行された場合、画像は保存され、`download imgs/gpt-4o.jpg` または `download imgs/gpt-4o-mini.jpg` を使用してダウンロードできます。

## モデルのトークン使用量を比較する

最後に、3 番目のスクリプトを実行します。これは、各モデルで処理されたトークンの数を時間の経過とともにプロットします。 このデータは Azure Monitor から取得されます。

1. 最後のスクリプトを実行する前に、Azure portal から Azure AI Foundry リソースのリソース ID をコピーする必要があります。 Azure AI Foundry リソースの概要ページに移動し、**JSON ビュー**を選択します。 リソース ID をコピーし、コード ファイル内の `your_resource_id` プレースホルダーを置き換えます。

    ```powershell
   code plot.py
    ```

1. 変更を保存。

1. コード エディターの下にある Cloud Shell コマンド ライン ペインで、次のコマンドを入力して、**3 番目**のスクリプトを実行します。

    ```powershell
   python plot.py
    ```

1. スクリプトが完了したら、次のコマンドを入力してメトリックのプロットをダウンロードします。

    ```powershell
   download imgs/plot.png
    ```

## まとめ

プロットを確認した後、以前に観察した正確性とコストのグラフのベンチマーク値を思い出したら、どのモデルがユースケースに最適であるかを決定できますか?  出力の精度の違いは、生成されるトークンの違い、したがってコストの違いを上回りますか?

## クリーンアップ

Azure AI サービスを確認し終わったら、不要な Azure コストが発生しないように、この演習で作成したリソースを削除する必要があります。

1. Azure portal が表示されているブラウザー タブに戻り (または、新しいブラウザー タブで [Azure portal](https://portal.azure.com?azure-portal=true) をもう一度開き)、この演習で使ったリソースがデプロイされているリソース グループの内容を表示します。
1. ツール バーの **[リソース グループの削除]** を選びます。
1. リソース グループ名を入力し、削除することを確認します。
